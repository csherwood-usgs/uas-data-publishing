{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "from scipy.interpolate import interp1d\n",
    "from PIL import Image, ExifTags\n",
    "# import datetime as dt\n",
    "import pytz\n",
    "from datetime import datetime as DT\n",
    "import pandas as pd\n",
    "from lxml import etree\n",
    "from dateutil import parser"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Input variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# unique to local files:\n",
    "homedir = r'/Users/emilysturdivant/Desktop/uas_data'\n",
    "logfile = os.path.join(homedir, 'f8.gpx')\n",
    "imagefolder = os.path.join(homedir, 'f8')\n",
    "rename_photos = False\n",
    "\n",
    "# Mission info - would be nice for logfile and image folder names to correspond to naming convention, as below\n",
    "survey_id = '2016-010FA'\n",
    "uas_id = 'u031'\n",
    "fc_id = 'f04r01'\n",
    "\n",
    "# Standard:\n",
    "namespace = {'def': 'http://www.topografix.com/GPX/1/1'}\n",
    "tfmt_exif = '%Y:%m:%d %H:%M:%S'\n",
    "# tfmt_gpx = '%Y-%m-%dT%H:%M:%S-04:00' #2017-05-04T14:14:12-04:00\n",
    "iso_fmt=\"%Y%m%dT%H%M%SZ\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def dt_to_UTCval(dtstr, fmt, local_tz='US/Eastern'):\n",
    "    time = (pytz.timezone(local_tz).localize(DT.strptime(e.text, tfmt_gpx), is_dst=None)\n",
    "                                .astimezone(pytz.utc)\n",
    "                                .timestamp())\n",
    "    return(time)\n",
    "\n",
    "def gpx_tag_to_pdseries(tree, namespace, tag):\n",
    "    elist = tree.xpath('./def:trk//def:trkpt//def:'+tag, namespaces=namespace)\n",
    "    ser = pd.Series([e.text for e in elist], name=tag)\n",
    "    return(ser)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Parse GPX and extract components into dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[datetime.datetime(2017, 6, 13, 10, 38, 22, tzinfo=tzoffset(None, -14400)), datetime.datetime(2017, 6, 13, 10, 38, 22, tzinfo=tzoffset(None, -14400)), datetime.datetime(2017, 6, 13, 10, 38, 22, tzinfo=tzoffset(None, -14400)), datetime.datetime(2017, 6, 13, 10, 38, 23, tzinfo=tzoffset(None, -14400))]\n",
      "[datetime.datetime(2017, 6, 13, 14, 38, 22, tzinfo=<UTC>), datetime.datetime(2017, 6, 13, 14, 38, 22, tzinfo=<UTC>), datetime.datetime(2017, 6, 13, 14, 38, 22, tzinfo=<UTC>), datetime.datetime(2017, 6, 13, 14, 38, 23, tzinfo=<UTC>)]\n"
     ]
    }
   ],
   "source": [
    "# Parse GPX and extract components into dataframe\n",
    "tree = etree.parse(logfile)\n",
    "\n",
    "# latitude and longitude\n",
    "elist = tree.xpath('./def:trk//def:trkpt',namespaces=namespace)\n",
    "gpxdf = pd.DataFrame([e.values() for e in elist], columns=['lat', 'lon'])\n",
    "\n",
    "# all other tags\n",
    "taglist = ['ele', 'ele2', 'course', 'roll', 'pitch', 'mode']\n",
    "for tag in taglist:\n",
    "    gpxdf = gpxdf.join(gpx_tag_to_pdseries(tree, namespace, tag))\n",
    "\n",
    "# time\n",
    "tag = 'time'\n",
    "elist = tree.xpath('./def:trk//def:trkpt//def:'+tag, namespaces=namespace)\n",
    "dt = [parser.parse(e.text) for e in elist] # parser will detect time zones\n",
    "dtz = [dti.astimezone(pytz.utc) for dti in dt]\n",
    "gpxdf = gpxdf.join(pd.DataFrame({'time_utc':dtz, 'time_epoch': [t.timestamp() for t in dtz]}))\n",
    "\n",
    "# gpxdf.head()\n",
    "\n",
    "# Export CSV: logfile_gpx.csv stored in same folder as logfile\n",
    "gpxdf.to_csv(os.path.splitext(logfile)[0]+'_gpx.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Export CSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%% PLOT!\n",
    "fig = plt.figure()\n",
    "ax = fig.add_subplot(111)\n",
    "ax.axis([-75.7502, -75.7543, 36.18135, 36.1865])\n",
    "\n",
    "ax.plot(gpxdf.lon,gpxdf.lat,'-')\n",
    "# plt.show()\n",
    "fig.savefig(os.path.join(homedir, \"plot_gpxtrack.png\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Work with images\n",
    "Replace original images because this will consider current filenames \"original\" and will replace. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 188 images in /Users/emilysturdivant/Desktop/uas_data/f8.\n",
      "First... file: B0009085.JPG, time: 2017-06-13 14:34:54+00:00\n",
      "Last... file: B0009316.JPG, time: 2017-06-13 14:49:00+00:00\n",
      "/Users/emilysturdivant/Desktop/uas_data/f8.gpx from 2017-06-13 14:38:22+00:00 to 2017-06-13 14:55:08+00:00\n"
     ]
    }
   ],
   "source": [
    "# List all JPEGS in imagefolder\n",
    "flist=[os.path.join(imagefolder,f) for f in os.listdir(imagefolder) if f.lower().endswith('.jpg')]\n",
    "print(\"Found {} images in {}.\".format(len(flist),imagefolder))\n",
    "\n",
    "# Get filename and DateTimeOriginal of each photo\n",
    "#FIXME: how to get tzinfo from EXIF? Looks like these were recorded in UTC...\n",
    "dt = [pytz.utc.localize(DT.strptime(Image.open(f)._getexif()[36867], tfmt_exif)) for f in flist] # make timezone aware (UTC) for later comparison with GPX times\n",
    "imgdf = pd.DataFrame({'orig_name': [os.path.basename(f) for f in flist],\n",
    "                      'time_utc': dt,\n",
    "                      'time_epoch': [t.timestamp() for t in dt],\n",
    "                      'time_iso': [t.strftime(iso_fmt) for t in dt],\n",
    "                      'new_name': np.nan,\n",
    "                      'lon': np.nan,\n",
    "                      'lat': np.nan,\n",
    "                      'ele': np.nan,\n",
    "                      'interpolated': 0})\n",
    "# imgdf.head()\n",
    "\n",
    "# Export CSV\n",
    "imgdf.to_csv(imagefolder+'_EXIFtime.csv', index=False)\n",
    "\n",
    "# print first and last image name and times\n",
    "print(\"First... file: {}, time: {}\".format(imgdf.orig_name.iloc[0],imgdf.time_utc.iloc[0]))\n",
    "print(\"Last... file: {}, time: {}\".format(imgdf.orig_name.iloc[-1],imgdf.time_utc.iloc[-1]))\n",
    "# print first and last times in .gpx file\n",
    "print(\"{} from {} to {}\".format(logfile, gpxdf.time_utc.iloc[0],gpxdf.time_utc.iloc[-1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Rename photos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Rename photos\n",
    "#TODO move/copy them first? / don't run if the names have already been changed...\n",
    "for idx, row in imgdf.iterrows():\n",
    "    img = row.orig_name\n",
    "    namestr = \"{}_{}_{}_{}_{}\".format(survey_id, uas_id, fc_id, row.time_iso, img) # ->\n",
    "    if rename_photos:\n",
    "        os.rename(os.path.join(imagefolder, img), os.path.join(imagefolder, namestr))\n",
    "    imgdf.loc[idx, 'new_name'] = namestr"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Interpolation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPS start: 1497364702.0\n",
      "GPS end: 1497365708.0\n",
      "1 image(s) not acquired between 1497364702.0 and 1497365708.0:\n",
      "B0009085.JPG\n"
     ]
    }
   ],
   "source": [
    "# set up interpolation \n",
    "# Datetime objects can be compared, but both need to be either tz-aware or unaware\n",
    "# Datetime objects cannot be used for interpolation with interp1\n",
    "timecol = 'time_epoch'\n",
    "\n",
    "# get GPS bounds\n",
    "start_gpxtime = gpxdf[timecol].min()\n",
    "end_gpxtime = gpxdf[timecol].max()\n",
    "print('GPS start: {}\\nGPS end: {}'.format(start_gpxtime, end_gpxtime))\n",
    "\n",
    "# create interpolator\n",
    "set_interp = interp1d(gpxdf[timecol], gpxdf[['lat','lon','ele']], kind='linear', axis=0) # this works\n",
    "\n",
    "# loop through the images and interpolate .gpx data\n",
    "img_nogps = []\n",
    "for idx, row in imgdf.iterrows():\n",
    "    img_tznum = row.loc[timecol]\n",
    "    if img_tznum >= start_gpxtime and img_tznum <= end_gpxtime:\n",
    "        imgdf.loc[idx, ['lat','lon','ele']] = set_interp(img_tznum)\n",
    "    else: # image time is not within .gpx data\n",
    "        imgdf.loc[idx, ['lat','lon','ele']] = np.nan\n",
    "        img_nogps.append(row.orig_name)\n",
    "print('{} image(s) not acquired between {} and {}:'.format(len(img_nogps), start_gpxtime, end_gpxtime))\n",
    "[print(img) for img in img_nogps]\n",
    "\n",
    "# Set interpolated value where no GPS time at image time\n",
    "missing_idx = ~(imgdf[timecol].isin(gpxdf[timecol])) # All images with time logged by GPS\n",
    "imgdf.loc[missing_idx, 'interpolated'] = 1\n",
    "\n",
    "# Export CSV\n",
    "imgdf.to_csv(imagefolder+'_EXIFtime.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make a bare-bones trackline and overlay image locations, sherwood direct\n",
    "#%% Plot image locations\n",
    "fig = plt.figure()\n",
    "ax = fig.add_subplot(111)\n",
    "ax.axis([-75.7502, -75.7543, 36.18135, 36.1865])\n",
    "ax.plot(gpxdf.lon, gpxdf.lat,'.r')\n",
    "ax.plot(imgdf.lon, imgdf.lat,'-')\n",
    "# plt.show()\n",
    "fig.savefig(os.path.join(homedir, \"image_track.png\"))\n",
    "\n",
    "#%% Plot\n",
    "fig = plt.figure()\n",
    "ax = fig.add_subplot(111)\n",
    "\n",
    "ax.plot(gpxdf.time_utc, gpxdf.ele,'.r')\n",
    "ax.plot(imgdf.time_utc, imgdf.ele,'-')\n",
    "# plt.show()\n",
    "fig.savefig(os.path.join(homedir, \"image_elevations.png\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/emilysturdivant/anaconda/envs/IOOS3/lib/python3.6/site-packages/pandas/core/frame.py:2746: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  **kwargs)\n"
     ]
    }
   ],
   "source": [
    "# print out file name, time, and data\n",
    "# TODO - write a .csv file with columns in the correct order for Photoscan\n",
    "# photoscan_cols = ['Label', 'X', 'Y', 'Z']\n",
    "psdf = imgdf.loc[:,['new_name','lon','lon','ele']]\n",
    "psdf.rename(columns={'new_name':'Label', 'lon':'X', 'lon':'Y', 'ele':'Z'}, inplace=True)\n",
    "psdf.to_csv(os.path.join(homedir,'cam_locations.txt'), index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # experiments:\n",
    "# # select images with a matching GPS time and those without\n",
    "# matches = imgdf[imgdf[timecol].isin(gpxdf[timecol])] # All images with time logged by GPS\n",
    "# missing_idx = ~(imgdf[timecol].isin(gpxdf[timecol])) # All images with time logged by GPS\n",
    "# imgdf.loc[missing_idx, 'interpolated'] = 1\n",
    "# print('Images with exact GPS time match: ', matches.shape[0])\n",
    "# print('Images without exact GPS time match: ', missing.shape[0])\n",
    "\n",
    "# # set up interpolation \n",
    "# # gpx4interp = gpxdf[['lat','lon','ele']]\n",
    "# # set_interp = interp1d(gpxdf[timecol], gpx4interp, kind='linear', axis=0)\n",
    "# # imgdf.apply(set_interp(timecol), axis=1)\n",
    "\n",
    "# # gpxdf.interpolate(method='time') \n",
    "# # # for use filling NaNs: nans in gaps in data, then interpolate, \n",
    "# # # 'time' interpolation works on daily and higher resolution data to interpolate given length of interval\n",
    "# # # axis: # 0: fill column-by-column # 1: fill row-by-row\n",
    "# # #set time to index, then reindex to consistent time steps, it will add missing times and put nan values; then use apply to interpolate\n",
    "# timecol = 'time_utc'\n",
    "# # drop duplicate time values; alternative: add specificity to them... \n",
    "# df_deduped = gpxdf.drop_duplicates(subset=timecol, keep='first')\n",
    "# df = df_deduped.set_index(timecol)\n",
    "# df_reindexed = df.reindex(pd.date_range(start=df.index.min(),end=df.index.max()), copy=True)  \n",
    "# df_reindexed.index\n",
    "# # print(df.index.min(), df.index.max())\n",
    "# # df_reindexed.head()\n",
    "# df_reindexed.interpolate(method='linear')  \n",
    "\n",
    "# # df2 = df.reindex(arange(time))\n",
    "# # df2.apply(pandas.Series.interpolate)\n",
    "\n",
    "# # # alternative:\n",
    "# # def getExtrapolatedInterpolatedValue(x, y):\n",
    "# #     global dataGrid\n",
    "# #     if x not in dataGrid.index:\n",
    "# #         dataGrid.ix[x] = nan\n",
    "# #         dataGrid = dataGrid.sort()\n",
    "# #         dataGrid = dataGrid.interpolate(method='index', axis=0).ffill(axis=0).bfill(axis=0)\n",
    "\n",
    "# #     if y not in dataGrid.columns.values:\n",
    "# #         dataGrid = dataGrid.reindex(columns=numpy.append(dataGrid.columns.values, y))\n",
    "# #         dataGrid = dataGrid.sort_index(axis=1)\n",
    "# #         dataGrid = dataGrid.interpolate(method='index', axis=1).ffill(axis=1).bfill(axis=1)\n",
    "\n",
    "# #     return dataGrid[y][x]\n",
    "# # print getExtrapolatedInterpolatedValue(2, 1.4)\n",
    "# # #\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:IOOS3]",
   "language": "python",
   "name": "conda-env-IOOS3-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
